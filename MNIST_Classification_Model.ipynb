{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "TluHnOpnc_QS",
        "twl3msL-i2F_",
        "YDv6EzaUCvVj",
        "vzLZPObUCyib",
        "u7DzGiNKC1xA",
        "QxLAA4mnC5GM",
        "cllR9roaGilv",
        "IWYwX367HwM-",
        "jkjlIgl5H5l1",
        "8GKlPNNiShFf",
        "O2pmGSS3On-5"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Multi-layer NN for Digit Classification using MNIST"
      ],
      "metadata": {
        "id": "TluHnOpnc_QS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- MNIST\n",
        "- Dataloader to load dataset\n",
        "- Apply Transformation\n",
        "- Implement Multilayer NN with activation functions\n",
        "- Set up loss and optimizer\n",
        "- Training Loop (Batch Training)\n",
        "- Evaluate Model\n",
        "- GPU Support\n",
        "- TensorBoard\n",
        "- Save & Load Model"
      ],
      "metadata": {
        "id": "7vOVznT0dLy8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Setting up TensorBoard:"
      ],
      "metadata": {
        "id": "twl3msL-i2F_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorboard"
      ],
      "metadata": {
        "id": "UZMljaODilYr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "e3agYXxvcKFj"
      },
      "outputs": [],
      "source": [
        "# Load the TensorBoard notebook extension\n",
        "\n",
        "%load_ext tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf ./myLogs/ # Clear any logs from previous runs"
      ],
      "metadata": {
        "id": "f3TOHklyfmSl"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorboard --logdir myLogs/fit #To start tensorBoard"
      ],
      "metadata": {
        "id": "9Qd7MQnogFhC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Importing Libraries:"
      ],
      "metadata": {
        "id": "YDv6EzaUCvVj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "hza5q3VJBIto"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import classification_report\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import sys"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "writer = SummaryWriter(\"myLogs/fit/MNIST\")"
      ],
      "metadata": {
        "id": "-Hihx1zLgkFB"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Device Configuration:"
      ],
      "metadata": {
        "id": "vzLZPObUCyib"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#device config\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "#if gpu available name it cuda otherwise cpu\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PLiKyDkWCFBj",
        "outputId": "878e0b2e-1ad7-4609-af9f-ca8c8263040c"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Hyper Parameters:"
      ],
      "metadata": {
        "id": "u7DzGiNKC1xA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#hyper parameters\n",
        "input_size = 784 #because image size is 28 * 28 = 784\n",
        "hidden_size = 100\n",
        "num_classes = 10 #digits 0 - 9\n",
        "num_epochs = 2\n",
        "batch_size = 100\n",
        "learning_rate = 0.001"
      ],
      "metadata": {
        "id": "arCRzTubCWX7"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Importing MNIST Dataset:"
      ],
      "metadata": {
        "id": "QxLAA4mnC5GM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#MNIST\n",
        "#training set\n",
        "train_dataset = torchvision.datasets.MNIST(\n",
        "    root=\"/data\", #path for storing dataset\n",
        "    train=True, #implies it is training dataset\n",
        "    transform=transforms.ToTensor(), #applying transformation\n",
        "    download=True) #download dataset if it's not available"
      ],
      "metadata": {
        "id": "RP3ZUW1HCtkG"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#testing set\n",
        "test_dataset = torchvision.datasets.MNIST(\n",
        "    root=\"/data\", #path for accessing dataset\n",
        "    train=False, #implies it is testing dataset\n",
        "    transform=transforms.ToTensor()) #applying transformation\n",
        "    #dataset already downloaded"
      ],
      "metadata": {
        "id": "CxNSYL78DkwH"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#DataLoader\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    dataset=train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    dataset=test_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False)"
      ],
      "metadata": {
        "id": "Y-2T57AoDzjG"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "examples = iter(train_loader)\n",
        "samples, labels = next(examples)\n",
        "print(samples.shape, labels.shape) #batch size is 100, channel is 1, 28 x 28 image size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LZvE0OIvELxb",
        "outputId": "ba49df0c-faa8-47a3-db90-5916bbf4ff81"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([100, 1, 28, 28]) torch.Size([100])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(6):\n",
        "  plt.subplot(2,3, i+1) #divides the fig in 2 rows, 3 columns\n",
        "  #i+1 specifies position of current sub plot\n",
        "  plt.imshow(samples[i][0], cmap='gray') #cmap = gray, displays image in grayscale\n",
        "#plt.show()"
      ],
      "metadata": {
        "id": "yxxMlj8xFTGP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_grid = torchvision.utils.make_grid(samples)\n",
        "writer.add_image(\"mnist_images\", img_grid) #adding image to tensorboard\n",
        "writer.close()"
      ],
      "metadata": {
        "id": "ffULhq6srKW8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorboard --logdir myLogs/fit #To start tensorBoard"
      ],
      "metadata": {
        "id": "BviBb9oyl1va"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Neural Network:"
      ],
      "metadata": {
        "id": "cllR9roaGilv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NN(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, num_classes):\n",
        "    super(NN, self).__init__()\n",
        "    self.l1 = nn.Linear(input_size, hidden_size)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.l2 = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = self.l1(x)\n",
        "    out = self.relu(out)\n",
        "    out = self.l2(out)\n",
        "    #no need to apply softmax\n",
        "    #we will use cross entropy loss function which automatically applies softmax\n",
        "    return out"
      ],
      "metadata": {
        "id": "rBHglCAZGk0Q"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = NN(input_size, hidden_size, num_classes).to(device)"
      ],
      "metadata": {
        "id": "ctSB9VjZHoEj"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Loss & Optimizer:"
      ],
      "metadata": {
        "id": "IWYwX367HwM-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Loss & Optimizer:\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "aHqZyaoIHYIa"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "writer.add_graph(model, samples.reshape(-1, 28*28)) #adding model graph to tensorboard\n",
        "writer.close()"
      ],
      "metadata": {
        "id": "yyL18WB4kbGL"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorboard --logdir myLogs/fit #To start tensorBoard"
      ],
      "metadata": {
        "id": "ZL1Ho99-l33e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Training Loop:"
      ],
      "metadata": {
        "id": "jkjlIgl5H5l1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_total_steps = len(train_loader) #60000 (total samples) / 100 (batch size) = 600\n",
        "\n",
        "running_loss = 0.0\n",
        "running_correct = 0\n",
        "\n",
        "for epoch in range(num_epochs): #iterate through epochs\n",
        "  running_loss = 0.0  # Track loss for the epoch\n",
        "  for i, (images, labels) in enumerate(train_loader): #iterate through batches\n",
        "    #shape: [100, 1, 28, 28]\n",
        "    #input_size = 784\n",
        "    #image tensor needs [100, 784]\n",
        "\n",
        "    #reshaping:\n",
        "    images = images.reshape(-1, 28*28).to(device) #pushes to gpu if available\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    #forward\n",
        "    outputs = model(images)\n",
        "    loss = criterion(outputs, labels)\n",
        "\n",
        "    #backward\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    running_loss += loss.item()\n",
        "\n",
        "    _, predictions = torch.max(outputs, 1)\n",
        "\n",
        "    running_correct += (predictions == labels).sum().item()\n",
        "\n",
        "    if(i+1) % 100 == 0:\n",
        "      print(f'epoch: {epoch + 1} / {num_epochs}, step: {i+1} / {n_total_steps}, loss = {loss.item():.4f}')\n",
        "      writer.add_scalar('Training Loss', running_loss / 100, epoch * n_total_steps + i) #For each 100 steps, add training loss to tensorboard\n",
        "      writer.add_scalar('Accuracy', running_correct / 100, epoch * n_total_steps + i) #add accuracy to tensorboard\n",
        "      running_loss = 0.0\n",
        "      running_correct = 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "feaNOm0mH7b7",
        "outputId": "896798de-ee83-4600-f6d4-70befc422949"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 1 / 2, step: 100 / 600, loss = 0.4212\n",
            "epoch: 1 / 2, step: 200 / 600, loss = 0.2478\n",
            "epoch: 1 / 2, step: 300 / 600, loss = 0.4007\n",
            "epoch: 1 / 2, step: 400 / 600, loss = 0.3441\n",
            "epoch: 1 / 2, step: 500 / 600, loss = 0.3218\n",
            "epoch: 1 / 2, step: 600 / 600, loss = 0.2702\n",
            "epoch: 2 / 2, step: 100 / 600, loss = 0.2043\n",
            "epoch: 2 / 2, step: 200 / 600, loss = 0.1693\n",
            "epoch: 2 / 2, step: 300 / 600, loss = 0.1559\n",
            "epoch: 2 / 2, step: 400 / 600, loss = 0.2066\n",
            "epoch: 2 / 2, step: 500 / 600, loss = 0.2217\n",
            "epoch: 2 / 2, step: 600 / 600, loss = 0.3011\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "writer.close()"
      ],
      "metadata": {
        "id": "i-Ub6Ia4o36x"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Evaluate Model:"
      ],
      "metadata": {
        "id": "8GKlPNNiShFf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#for precision & recall:\n",
        "labels = []\n",
        "preds = []"
      ],
      "metadata": {
        "id": "-lQKiGGtrCOe"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#test\n",
        "with torch.no_grad():\n",
        "  n_correct = 0 #no. of correct predictions\n",
        "  n_samples = 0\n",
        "  n_class_correct = [0 for i in range(10)]\n",
        "  n_class_samples = [0 for i in range(10)]\n",
        "\n",
        "  for images, labels1 in test_loader:\n",
        "    images = images.reshape(-1, 28 * 28).to(device)\n",
        "    labels1 = labels1.to(device)\n",
        "    outputs = model(images)\n",
        "\n",
        "    #torch.max returns max value(highest probability) and its index(class label)\n",
        "    _, predictions = torch.max(outputs, 1)\n",
        "    n_samples += labels1.shape[0] #no. of samples in current batch\n",
        "    n_correct += (predictions == labels1).sum().item() #+1 for each correct prediction\n",
        "\n",
        "    labels.append(predictions)\n",
        "\n",
        "    #since output of model is in raw values, we need to convert it to probabilites (value b/w 0 & 1)\n",
        "    class_preds = [F.softmax(output, dim=0) for output in outputs] #using softmax to convert to probabilities\n",
        "    preds.append(class_preds)\n",
        "\n",
        "  labels = torch.cat(labels) #converting from list to 1D tensor\n",
        "  preds = torch.cat([torch.stack(batch) for batch in preds]) #converting to 2D tensor\n",
        "\n",
        "  classes = range(10)\n",
        "\n",
        "  for i in classes:\n",
        "    labels_i = labels == i\n",
        "    preds_i = preds[:, i]\n",
        "    writer.add_pr_curve(str(i), labels_i, preds_i, global_step=0)\n",
        "    writer.close\n",
        "\n",
        "  acc = 100.0 * n_correct / n_samples\n",
        "  print(f'accuracy = {acc}')"
      ],
      "metadata": {
        "id": "iWMLs5n8JT19"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Save & Load Model:"
      ],
      "metadata": {
        "id": "O2pmGSS3On-5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save model parameters\n",
        "torch.save(model.state_dict(), \"MNIST_Model_Parameters.pt\")"
      ],
      "metadata": {
        "id": "Jh6z-RzxOq8q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Load model:\n",
        "loaded_model = NN(input_size, hidden_size, num_classes)\n",
        "loaded_model.load_state_dict(torch.load(\"MNIST_Model_Parameters.pt\"))\n",
        "loaded_model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vvwUh_lWPF84",
        "outputId": "48533a37-7848-4bc1-e9d7-7966a4136a77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-a3e2f201ecf5>:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  loaded_model.load_state_dict(torch.load(\"MNIST_Model_Parameters.pt\"))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NN(\n",
              "  (l1): Linear(in_features=784, out_features=100, bias=True)\n",
              "  (relu): ReLU()\n",
              "  (l2): Linear(in_features=100, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the loaded model\n",
        "with torch.no_grad():\n",
        "  n_correct = 0 #no. of correct predictions\n",
        "  n_samples = 0\n",
        "\n",
        "  for images, labels in test_loader:\n",
        "    images = images.reshape(-1, 28 * 28).to(device)\n",
        "    labels = labels.to(device)\n",
        "    outputs = model(images)\n",
        "\n",
        "    #torch.max returns max value(highest probability) and its index(class label)\n",
        "    _, predictions = torch.max(outputs, 1)\n",
        "    n_samples += labels.shape[0] #no. of samples in current batch\n",
        "    n_correct += (predictions == labels).sum().item() #+1 for each correct prediction\n",
        "\n",
        "  acc = 100.0 * n_correct / n_samples\n",
        "  print(f'accuracy = {acc}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qLcXIlSFPTnS",
        "outputId": "16e811a5-61e5-4bfb-f3b5-a69319d066ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy = 95.28\n"
          ]
        }
      ]
    }
  ]
}